# VoiceQuiz êµ¬í˜„ ë…¸íŠ¸

## ðŸš¨ ì¤‘ìš” ìˆ˜ì •ì‚¬í•­

### 1. Session Config êµ¬ì¡° (Cloud Run ì„œë²„)

ì œê³µí•˜ì‹  ì½”ë“œë¥¼ OpenAI Realtime API GA ë¬¸ì„œì— ë§žì¶° ìˆ˜ì •:

```javascript
// index.js - ìˆ˜ì •ëœ ë²„ì „
import express from "express";

const app = express();
app.use(express.json());

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
if (!OPENAI_API_KEY) throw new Error("Missing OPENAI_API_KEY");

const PORT = process.env.PORT || 8080;

// Instructions ìƒì„± í•¨ìˆ˜ (gameModeë³„)
function generateInstructions(gameMode, currentWord, tabooWords) {
  if (gameMode === "modeA") {
    // AIê°€ ì„¤ëª…ìž ì—­í• 
    return `# Role
You are the host of a speed quiz game. Your job is to describe words so the user can guess them.

# Rules
- NEVER say the target word, its spelling, or direct synonyms
- Use indirect, natural descriptions like "You use this when..." or "You usually see this in..."
- Keep descriptions SHORT (1-2 sentences at a time)
- If the user says something close, provide additional hints
- If the user is correct, immediately stop and wait for the next word
- The taboo words for the current word are: ${tabooWords?.join(", ") || "none"}

# Current Word
The word you need to describe is: ${currentWord}

# Language
- Speak only in English
- Use clear, natural pronunciation`;
  } else if (gameMode === "modeB") {
    // AIê°€ ì¶”ì¸¡ìž ì—­í• 
    return `# Role
You are a player in a speed quiz game trying to GUESS the word based on the user's description.

# Rules
- NEVER ask questions like "Is it...?" or "Does it...?"
- ONLY make direct guesses in the format: "I think it is [WORD]" or simply "[WORD]"
- Listen carefully to the user's description
- Make educated guesses based on the clues
- If you get "Close" feedback, try related words
- If you get "Incorrect" feedback, try completely different words
- Keep your guesses SHORT and CLEAR

# Language
- Listen in English
- Respond only in English
- Use clear, natural pronunciation`;
  }
  return "You are a helpful assistant.";
}

app.post("/token", async (req, res) => {
  try {
    const { deviceId, platform, appVersion, gameMode, currentWord, tabooWords } = req.body;

    // ë¡œê¹…
    console.log(`[${new Date().toISOString()}] Token request - device: ${deviceId}, mode: ${gameMode}, word: ${currentWord}`);

    // âš ï¸ ì¤‘ìš”: WebRTC í™˜ê²½ì—ì„œëŠ” format í•„ë“œ ìƒëžµ ê¶Œìž¥
    // SDP í˜‘ìƒ ê³¼ì •ì—ì„œ ìžë™ìœ¼ë¡œ ì½”ë±(Opus)ê³¼ ìƒ˜í”Œë§ ë ˆì´íŠ¸ê°€ ê²°ì •ë¨
    const sessionConfig = {
      session: {
        type: "realtime",
        model: "gpt-realtime",
        instructions: generateInstructions(gameMode, currentWord, tabooWords),
        audio: {
          input: {
            // format ìƒëžµ - WebRTC SDPì—ì„œ ìžë™ í˜‘ìƒ
            turn_detection: {
              type: "semantic_vad",
              // threshold: 0.5,  // ê¸°ë³¸ê°’, í•„ìš”ì‹œ ì¡°ì •
              // silence_duration_ms: 200,
              // prefix_padding_ms: 300,
            },
            transcription: {
              model: "whisper-1",
            },
          },
          output: {
            // format ìƒëžµ - WebRTC SDPì—ì„œ ìžë™ í˜‘ìƒ
            voice: "marin",
          },
        },
      },
    };

    const response = await fetch(
      "https://api.openai.com/v1/realtime/client_secrets",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify(sessionConfig),
      }
    );

    if (!response.ok) {
      const errText = await response.text();
      console.error("OpenAI API error:", response.status, errText);
      return res.status(response.status).json({
        error: "client_secrets failed",
        details: errText
      });
    }

    const data = await response.json();
    console.log(`[${new Date().toISOString()}] Token issued - expires: ${data.expires_at}`);

    // ì‘ë‹µ ê·¸ëŒ€ë¡œ ì „ë‹¬
    res.json(data);
  } catch (error) {
    console.error("Token generation error:", error);
    res.status(500).json({ error: "Internal server error" });
  }
});

app.get("/health", (req, res) => {
  res.json({ status: "ok", timestamp: new Date().toISOString() });
});

app.listen(PORT, () => {
  console.log(`Server running on port ${PORT}`);
});
```

### í•µì‹¬ ìˆ˜ì • ì‚¬í•­:

1. **`transcription` ìœ„ì¹˜**: `audio.input.transcription` (GA ë¬¸ì„œ ê¸°ì¤€)
2. **`turn_detection` ìœ„ì¹˜**: `audio.input.turn_detection`
3. **Audio format ëª…ì‹œ**: `audio/pcm`, rate 24000 (ê¶Œìž¥)
4. **Instructions ë™ì  ìƒì„±**: `gameMode`, `currentWord`, `tabooWords` ë°˜ì˜

---

## 2. iOS í´ë¼ì´ì–¸íŠ¸ ê°œì„ ì‚¬í•­

### A. RealtimeWebRTCClient.swift ì™„ì„±ë³¸

```swift
import Foundation
import WebRTC
import AVFoundation

final class RealtimeWebRTCClient: NSObject {

    // MARK: - Properties
    private var peerConnection: RTCPeerConnection?
    private var dataChannel: RTCDataChannel?
    private var audioTrack: RTCAudioTrack?
    private var factory: RTCPeerConnectionFactory!

    // Delegate for handling events
    weak var delegate: RealtimeWebRTCClientDelegate?

    // Current connection state
    private(set) var connectionState: RTCPeerConnectionState = .new

    // MARK: - Initialization
    override init() {
        super.init()
        RTCInitializeSSL()
        self.factory = RTCPeerConnectionFactory()
    }

    deinit {
        disconnect()
        RTCCleanupSSL()
    }

    // MARK: - Audio Session
    func configureAudioSession() throws {
        let session = AVAudioSession.sharedInstance()
        try session.setCategory(
            .playAndRecord,
            mode: .voiceChat,
            options: [.defaultToSpeaker, .allowBluetooth]
        )
        try session.setActive(true)
        print("âœ… Audio session configured")
    }

    // MARK: - PeerConnection Setup
    func createPeerConnection() {
        let config = RTCConfiguration()
        config.sdpSemantics = .unifiedPlan

        // STUN server (í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ ê¶Œìž¥)
        config.iceServers = [
            RTCIceServer(urlStrings: ["stun:stun.l.google.com:19302"])
        ]

        let constraints = RTCMediaConstraints(
            mandatoryConstraints: nil,
            optionalConstraints: ["DtlsSrtpKeyAgreement": "true"]
        )

        guard let pc = factory.peerConnection(
            with: config,
            constraints: constraints,
            delegate: self
        ) else {
            print("âŒ Failed to create peer connection")
            return
        }

        self.peerConnection = pc

        // Audio track ì¶”ê°€ (ë§ˆì´í¬)
        addAudioTrack(to: pc)

        // DataChannel ìƒì„± (oai-events)
        createDataChannel(on: pc)

        print("âœ… PeerConnection created")
    }

    private func addAudioTrack(to pc: RTCPeerConnection) {
        let audioConstraints = RTCMediaConstraints(
            mandatoryConstraints: nil,
            optionalConstraints: nil
        )
        let audioSource = factory.audioSource(with: audioConstraints)
        let audioTrack = factory.audioTrack(with: audioSource, trackId: "audio0")

        pc.add(audioTrack, streamIds: ["stream0"])
        self.audioTrack = audioTrack

        print("âœ… Audio track added")
    }

    private func createDataChannel(on pc: RTCPeerConnection) {
        let config = RTCDataChannelConfiguration()
        config.isOrdered = true

        let dc = pc.dataChannel(forLabel: "oai-events", configuration: config)
        dc?.delegate = self
        self.dataChannel = dc

        print("âœ… DataChannel created: oai-events")
    }

    // MARK: - Connection
    func connect(ephemeralKey: String) async throws {
        guard let pc = peerConnection else {
            throw RealtimeError.peerConnectionNotInitialized
        }

        print("ðŸ”„ Starting connection...")

        // 1. Create offer
        let offer = try await createOffer(pc: pc)
        print("âœ… Offer created")

        // 2. Set local description
        try await setLocalDescription(pc: pc, description: offer)
        print("âœ… Local description set")

        // 3. Wait for ICE gathering (ì¤‘ìš”!)
        try await waitForIceGatheringComplete()
        print("âœ… ICE gathering complete")

        // 4. Get final SDP
        guard let localSdp = pc.localDescription?.sdp else {
            throw RealtimeError.localSdpNotAvailable
        }

        // 5. POST to OpenAI /realtime/calls
        let answerSdp = try await postSdpToOpenAI(
            sdp: localSdp,
            ephemeralKey: ephemeralKey
        )
        print("âœ… Answer SDP received")

        // 6. Set remote description
        let answer = RTCSessionDescription(type: .answer, sdp: answerSdp)
        try await setRemoteDescription(pc: pc, description: answer)
        print("âœ… Remote description set")

        print("ðŸŽ‰ WebRTC connection established!")
    }

    private func createOffer(pc: RTCPeerConnection) async throws -> RTCSessionDescription {
        return try await withCheckedThrowingContinuation { continuation in
            let constraints = RTCMediaConstraints(
                mandatoryConstraints: nil,
                optionalConstraints: nil
            )

            pc.offer(for: constraints) { sdp, error in
                if let error = error {
                    continuation.resume(throwing: error)
                } else if let sdp = sdp {
                    continuation.resume(returning: sdp)
                } else {
                    continuation.resume(throwing: RealtimeError.offerCreationFailed)
                }
            }
        }
    }

    private func setLocalDescription(
        pc: RTCPeerConnection,
        description: RTCSessionDescription
    ) async throws {
        try await withCheckedThrowingContinuation { continuation in
            pc.setLocalDescription(description) { error in
                if let error = error {
                    continuation.resume(throwing: error)
                } else {
                    continuation.resume(returning: ())
                }
            }
        }
    }

    private func setRemoteDescription(
        pc: RTCPeerConnection,
        description: RTCSessionDescription
    ) async throws {
        try await withCheckedThrowingContinuation { continuation in
            pc.setRemoteDescription(description) { error in
                if let error = error {
                    continuation.resume(throwing: error)
                } else {
                    continuation.resume(returning: ())
                }
            }
        }
    }

    private func waitForIceGatheringComplete() async throws {
        // MVP: ê°„ë‹¨ížˆ 0.8ì´ˆ ëŒ€ê¸°
        // TODO: ì‹¤ì œë¡œëŠ” iceGatheringState ë³€ê²½ì„ ê°ì§€í•´ì„œ complete ì‹œ return
        try await Task.sleep(nanoseconds: 800_000_000)
    }

    private func postSdpToOpenAI(
        sdp: String,
        ephemeralKey: String
    ) async throws -> String {
        let url = URL(string: "https://api.openai.com/v1/realtime/calls")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/sdp", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(ephemeralKey)", forHTTPHeaderField: "Authorization")
        request.httpBody = sdp.data(using: .utf8)

        let (data, response) = try await URLSession.shared.data(for: request)

        guard let httpResponse = response as? HTTPURLResponse else {
            throw RealtimeError.invalidResponse
        }

        guard (200..<300).contains(httpResponse.statusCode) else {
            let body = String(data: data, encoding: .utf8) ?? ""
            print("âŒ OpenAI /calls error: \(httpResponse.statusCode)")
            print("   Response: \(body)")
            throw RealtimeError.openAICallsFailed(statusCode: httpResponse.statusCode, body: body)
        }

        guard let answerSdp = String(data: data, encoding: .utf8) else {
            throw RealtimeError.invalidSdpResponse
        }

        return answerSdp
    }

    // MARK: - Send Events via DataChannel
    func sendEvent(_ event: [String: Any]) {
        guard let dc = dataChannel,
              dc.readyState == .open else {
            print("âš ï¸ DataChannel not ready")
            return
        }

        do {
            let jsonData = try JSONSerialization.data(withJSONObject: event)
            let buffer = RTCDataBuffer(data: jsonData, isBinary: false)
            dc.sendData(buffer)
            print("ðŸ“¤ Event sent: \(event["type"] ?? "unknown")")
        } catch {
            print("âŒ Failed to send event: \(error)")
        }
    }

    // MARK: - Disconnect
    func disconnect() {
        dataChannel?.close()
        peerConnection?.close()

        dataChannel = nil
        peerConnection = nil
        audioTrack = nil

        print("ðŸ”Œ Disconnected")
    }
}

// MARK: - RTCPeerConnectionDelegate
extension RealtimeWebRTCClient: RTCPeerConnectionDelegate {
    func peerConnection(
        _ peerConnection: RTCPeerConnection,
        didChange stateChanged: RTCPeerConnectionState
    ) {
        connectionState = stateChanged
        print("ðŸ”— Connection state: \(stateChanged)")
        delegate?.realtimeClient(self, didChangeConnectionState: stateChanged)
    }

    func peerConnection(
        _ peerConnection: RTCPeerConnection,
        didChange newState: RTCIceConnectionState
    ) {
        print("ðŸ§Š ICE connection state: \(newState)")
    }

    func peerConnection(
        _ peerConnection: RTCPeerConnection,
        didChange newState: RTCIceGatheringState
    ) {
        print("ðŸ§Š ICE gathering state: \(newState)")
    }

    func peerConnection(
        _ peerConnection: RTCPeerConnection,
        didGenerate candidate: RTCIceCandidate
    ) {
        print("ðŸ§Š ICE candidate generated")
    }

    func peerConnection(
        _ peerConnection: RTCPeerConnection,
        didRemove candidates: [RTCIceCandidate]
    ) {
        print("ðŸ§Š ICE candidates removed")
    }

    func peerConnectionShouldNegotiate(_ peerConnection: RTCPeerConnection) {
        print("ðŸ”„ Should negotiate")
    }

    func peerConnection(
        _ peerConnection: RTCPeerConnection,
        didAdd stream: RTCMediaStream
    ) {
        print("ðŸŽµ Remote stream added")

        // Remote audio track ì²˜ë¦¬ (ìžë™ ìž¬ìƒë¨)
        if let audioTrack = stream.audioTracks.first {
            print("âœ… Remote audio track available")
            delegate?.realtimeClient(self, didReceiveRemoteAudioTrack: audioTrack)
        }
    }

    func peerConnection(
        _ peerConnection: RTCPeerConnection,
        didRemove stream: RTCMediaStream
    ) {
        print("ðŸŽµ Remote stream removed")
    }

    func peerConnection(
        _ peerConnection: RTCPeerConnection,
        didOpen dataChannel: RTCDataChannel
    ) {
        print("ðŸ“¡ DataChannel opened by remote")
        self.dataChannel = dataChannel
        dataChannel.delegate = self
    }
}

// MARK: - RTCDataChannelDelegate
extension RealtimeWebRTCClient: RTCDataChannelDelegate {
    func dataChannelDidChangeState(_ dataChannel: RTCDataChannel) {
        print("ðŸ“¡ DataChannel state: \(dataChannel.readyState.rawValue)")

        if dataChannel.readyState == .open {
            print("âœ… DataChannel is OPEN - ready to send/receive events")
            delegate?.realtimeClientDataChannelDidOpen(self)
        }
    }

    func dataChannel(
        _ dataChannel: RTCDataChannel,
        didReceiveMessageWith buffer: RTCDataBuffer
    ) {
        guard let text = String(data: buffer.data, encoding: .utf8) else {
            print("âš ï¸ Failed to decode DataChannel message")
            return
        }

        print("ðŸ“¥ Event received: \(text.prefix(100))...")

        // JSON íŒŒì‹±
        do {
            if let json = try JSONSerialization.jsonObject(with: buffer.data) as? [String: Any] {
                delegate?.realtimeClient(self, didReceiveEvent: json)
            }
        } catch {
            print("âŒ Failed to parse event JSON: \(error)")
        }
    }
}

// MARK: - Delegate Protocol
protocol RealtimeWebRTCClientDelegate: AnyObject {
    func realtimeClient(_ client: RealtimeWebRTCClient, didChangeConnectionState state: RTCPeerConnectionState)
    func realtimeClient(_ client: RealtimeWebRTCClient, didReceiveRemoteAudioTrack track: RTCAudioTrack)
    func realtimeClientDataChannelDidOpen(_ client: RealtimeWebRTCClient)
    func realtimeClient(_ client: RealtimeWebRTCClient, didReceiveEvent event: [String: Any])
}

// MARK: - Error Types
enum RealtimeError: LocalizedError {
    case peerConnectionNotInitialized
    case offerCreationFailed
    case localSdpNotAvailable
    case invalidResponse
    case invalidSdpResponse
    case openAICallsFailed(statusCode: Int, body: String)

    var errorDescription: String? {
        switch self {
        case .peerConnectionNotInitialized:
            return "PeerConnection not initialized. Call createPeerConnection() first."
        case .offerCreationFailed:
            return "Failed to create WebRTC offer"
        case .localSdpNotAvailable:
            return "Local SDP not available after setting local description"
        case .invalidResponse:
            return "Invalid HTTP response"
        case .invalidSdpResponse:
            return "Invalid SDP response from OpenAI"
        case .openAICallsFailed(let statusCode, let body):
            return "OpenAI /calls failed with status \(statusCode): \(body)"
        }
    }
}
```

### B. Token Service (iOS)

```swift
// TokenService.swift
import Foundation
import UIKit

class TokenService {
    private let baseURL: URL

    init(baseURL: URL) {
        self.baseURL = baseURL
    }

    func fetchEphemeralKey(
        gameMode: String,
        currentWord: String? = nil,
        tabooWords: [String]? = nil
    ) async throws -> TokenResponse {
        let url = baseURL.appendingPathComponent("/token")
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")

        let body: [String: Any] = [
            "deviceId": UIDevice.current.identifierForVendor?.uuidString ?? UUID().uuidString,
            "platform": "ios",
            "appVersion": Bundle.main.infoDictionary?["CFBundleShortVersionString"] as? String ?? "1.0.0",
            "gameMode": gameMode,
            "currentWord": currentWord ?? "",
            "tabooWords": tabooWords ?? []
        ]

        request.httpBody = try JSONSerialization.data(withJSONObject: body)

        let (data, response) = try await URLSession.shared.data(for: request)

        guard let httpResponse = response as? HTTPURLResponse else {
            throw TokenError.invalidResponse
        }

        guard (200..<300).contains(httpResponse.statusCode) else {
            let body = String(data: data, encoding: .utf8) ?? ""
            throw TokenError.serverError(statusCode: httpResponse.statusCode, message: body)
        }

        let tokenResponse = try JSONDecoder().decode(TokenResponse.self, from: data)
        return tokenResponse
    }
}

struct TokenResponse: Codable {
    let value: String
    let expiresAt: String?

    enum CodingKeys: String, CodingKey {
        case value
        case expiresAt = "expires_at"
    }
}

enum TokenError: LocalizedError {
    case invalidResponse
    case serverError(statusCode: Int, message: String)

    var errorDescription: String? {
        switch self {
        case .invalidResponse:
            return "Invalid response from token server"
        case .serverError(let statusCode, let message):
            return "Token server error (\(statusCode)): \(message)"
        }
    }
}
```

---

## 3. ì‚¬ìš© ì˜ˆì‹œ (SwiftUI)

```swift
// GameViewModel.swift (ì˜ˆì‹œ)
import Foundation
import Combine

@MainActor
class GameViewModel: ObservableObject {
    @Published var connectionState: String = "Disconnected"
    @Published var transcriptText: String = ""
    @Published var isConnecting: Bool = false

    private let tokenService: TokenService
    private let rtcClient: RealtimeWebRTCClient

    init(serverURL: URL) {
        self.tokenService = TokenService(baseURL: serverURL)
        self.rtcClient = RealtimeWebRTCClient()
        self.rtcClient.delegate = self
    }

    func startGame(mode: String, word: String, tabooWords: [String]) async {
        isConnecting = true

        do {
            // 1. Audio session ì„¤ì •
            try rtcClient.configureAudioSession()

            // 2. PeerConnection ìƒì„±
            rtcClient.createPeerConnection()

            // 3. Token ë°œê¸‰
            let tokenResponse = try await tokenService.fetchEphemeralKey(
                gameMode: mode,
                currentWord: word,
                tabooWords: tabooWords
            )

            // 4. WebRTC ì—°ê²°
            try await rtcClient.connect(ephemeralKey: tokenResponse.value)

            connectionState = "Connected"
        } catch {
            print("âŒ Connection failed: \(error)")
            connectionState = "Failed: \(error.localizedDescription)"
        }

        isConnecting = false
    }

    func sendEvent(type: String, payload: [String: Any] = [:]) {
        var event = payload
        event["type"] = type
        rtcClient.sendEvent(event)
    }
}

extension GameViewModel: RealtimeWebRTCClientDelegate {
    func realtimeClient(_ client: RealtimeWebRTCClient, didChangeConnectionState state: RTCPeerConnectionState) {
        connectionState = "\(state)"
    }

    func realtimeClient(_ client: RealtimeWebRTCClient, didReceiveRemoteAudioTrack track: RTCAudioTrack) {
        print("âœ… Remote audio ready")
    }

    func realtimeClientDataChannelDidOpen(_ client: RealtimeWebRTCClient) {
        print("âœ… DataChannel ready - can send events")
    }

    func realtimeClient(_ client: RealtimeWebRTCClient, didReceiveEvent event: [String: Any]) {
        guard let type = event["type"] as? String else { return }

        switch type {
        case "session.created":
            print("âœ… Session created")

        case "conversation.item.input_audio_transcription.completed":
            if let transcript = event["transcript"] as? String {
                transcriptText = transcript
                print("ðŸ“ User transcript: \(transcript)")
            }

        case "response.output_audio_transcript.delta":
            if let delta = event["delta"] as? String {
                transcriptText += delta
                print("ðŸ“ AI transcript delta: \(delta)")
            }

        case "response.output_audio_transcript.done":
            print("âœ… AI transcript complete: \(transcriptText)")

        default:
            print("ðŸ“¥ Event: \(type)")
        }
    }
}
```

---

## 4. ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Cloud Run
- [ ] `package.json` ìƒì„±
- [ ] `index.js` ìž‘ì„± (ìˆ˜ì •ëœ session config ì‚¬ìš©)
- [ ] `Dockerfile` ìž‘ì„±
- [ ] í™˜ê²½ ë³€ìˆ˜ `OPENAI_API_KEY` ì„¤ì •
- [ ] Cloud Run ë°°í¬: `gcloud run deploy`
- [ ] ë°°í¬ URL í™•ì¸ ë° `/health` í…ŒìŠ¤íŠ¸

### iOS
- [ ] `Podfile`ì— `GoogleWebRTC` ì¶”ê°€
- [ ] `pod install` ì‹¤í–‰
- [ ] `Info.plist`ì— ë§ˆì´í¬ ê¶Œí•œ ì¶”ê°€
- [ ] `RealtimeWebRTCClient.swift` êµ¬í˜„
- [ ] `TokenService.swift` êµ¬í˜„
- [ ] Server URLì„ ë°°í¬ëœ Cloud Run URLë¡œ ë³€ê²½
- [ ] ì‹¤ì œ ê¸°ê¸°ì—ì„œ í…ŒìŠ¤íŠ¸

---

## 5. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### Phase 1: ê¸°ë³¸ ì—°ê²°
1. Cloud Run `/health` ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
2. iOSì—ì„œ `/token` í˜¸ì¶œ â†’ `ek_...` ë°›ê¸°
3. WebRTC ì—°ê²° â†’ `connected` ìƒíƒœ í™•ì¸
4. DataChannel `open` í™•ì¸
5. ë§ˆì´í¬ ë§í•˜ê¸° â†’ ì „ì‚¬ ì´ë²¤íŠ¸ ìˆ˜ì‹  í™•ì¸
6. AI ì‘ë‹µ ë“£ê¸° í™•ì¸

### Phase 2: ê²Œìž„ ë¡œì§
7. Mode A: AI ì„¤ëª… ì‹œìž‘ í™•ì¸
8. Mode A: ì‚¬ìš©ìž ë°œí™” ì‹œ AI ì¤‘ë‹¨ í™•ì¸
9. Mode A: ì •ë‹µ íŒì • ë° ë‹¤ìŒ ë‹¨ì–´ ì´ë™
10. Mode B: ë‹¨ì–´ í‘œì‹œ ë° AI ì¶”ì¸¡ í™•ì¸
11. Mode B: íŒì • ë²„íŠ¼ ë™ìž‘ í™•ì¸

---

**ìž‘ì„±ì¼**: 2025-12-19
**ê¸°ë°˜**: ì œê³µí•˜ì‹  ì½”ë“œ + OpenAI Realtime API GA ë¬¸ì„œ
