# Input Audio Transcription í™œì„±í™” ê²€ì¦

## ì¤‘ìš”ì„±

Session configì—ì„œ `audio.input.transcription`ì„ ì„¤ì •í–ˆë”ë¼ë„, ì—°ê²° í›„ ì‹¤ì œë¡œ í™œì„±í™”ë˜ì—ˆëŠ”ì§€ **ë°˜ë“œì‹œ í™•ì¸**í•´ì•¼ í•©ë‹ˆë‹¤. ì „ì‚¬ê°€ í™œì„±í™”ë˜ì§€ ì•Šìœ¼ë©´ ê²Œì„ì˜ í•µì‹¬ ê¸°ëŠ¥(ì •ë‹µ íŒì •)ì´ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ê²€ì¦ ì ˆì°¨

### 1. Session Created ì´ë²¤íŠ¸ í™•ì¸

WebRTC ì—°ê²° ì§í›„ `session.created` ì´ë²¤íŠ¸ê°€ ìˆ˜ì‹ ë©ë‹ˆë‹¤. ì´ ì´ë²¤íŠ¸ì—ì„œ transcription ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤.

```swift
func handleServerEvent(_ event: [String: Any]) {
    guard let type = event["type"] as? String else { return }

    switch type {
    case "session.created":
        print("âœ… Session created")

        // Transcription ì„¤ì • í™•ì¸
        if let session = event["session"] as? [String: Any],
           let audio = session["audio"] as? [String: Any],
           let input = audio["input"] as? [String: Any],
           let transcription = input["transcription"] as? [String: Any],
           let model = transcription["model"] as? String {

            print("âœ… Transcription enabled: \(model)")
            // ì˜ˆìƒ: "whisper-1"

        } else {
            print("âš ï¸ Transcription NOT enabled - will activate manually")
            // ìˆ˜ë™ìœ¼ë¡œ í™œì„±í™” í•„ìš”
            activateTranscription()
        }

    // ... other cases
    }
}
```

### 2. Session Created ì´ë²¤íŠ¸ ì˜ˆì‹œ

**Transcriptionì´ í™œì„±í™”ëœ ê²½ìš°:**

```json
{
  "type": "session.created",
  "event_id": "event_123",
  "session": {
    "id": "sess_abc123",
    "object": "realtime.session",
    "model": "gpt-realtime",
    "audio": {
      "input": {
        "turn_detection": {
          "type": "semantic_vad",
          "threshold": 0.5,
          "silence_duration_ms": 200,
          "prefix_padding_ms": 300
        },
        "transcription": {
          "model": "whisper-1"
        }
      },
      "output": {
        "voice": "marin"
      }
    }
  }
}
```

**Transcriptionì´ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°:**

```json
{
  "type": "session.created",
  "session": {
    "audio": {
      "input": {
        "turn_detection": { "type": "semantic_vad" }
        // transcription í•„ë“œ ì—†ìŒ!
      },
      "output": { "voice": "marin" }
    }
  }
}
```

### 3. ìˆ˜ë™ìœ¼ë¡œ Transcription í™œì„±í™”

ë§Œì•½ `session.created`ì— transcriptionì´ ì—†ë‹¤ë©´, `session.update`ë¡œ í™œì„±í™”í•©ë‹ˆë‹¤.

```swift
func activateTranscription() {
    guard let dataChannel = dataChannel, dataChannel.readyState == .open else {
        print("âŒ DataChannel not ready")
        return
    }

    let event: [String: Any] = [
        "type": "session.update",
        "session": [
            "type": "realtime",
            "audio": [
                "input": [
                    "transcription": [
                        "model": "whisper-1"
                    ]
                ]
            ]
        ]
    ]

    do {
        let jsonData = try JSONSerialization.data(withJSONObject: event)
        let buffer = RTCDataBuffer(data: jsonData, isBinary: false)
        dataChannel.sendData(buffer)
        print("ğŸ“¤ session.update sent to activate transcription")
    } catch {
        print("âŒ Failed to send session.update: \(error)")
    }
}
```

### 4. Session Updated ì´ë²¤íŠ¸ í™•ì¸

`session.update`ë¥¼ ë³´ë‚¸ í›„ `session.updated` ì´ë²¤íŠ¸ê°€ ìˆ˜ì‹ ë˜ë©°, ì—…ë°ì´íŠ¸ëœ ì„¤ì •ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```swift
case "session.updated":
    print("âœ… Session updated")

    // ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ transcription í™•ì¸
    if let session = event["session"] as? [String: Any],
       let audio = session["audio"] as? [String: Any],
       let input = audio["input"] as? [String: Any],
       let transcription = input["transcription"] as? [String: Any] {

        print("âœ… Transcription now active: \(transcription)")
    }
```

## ì „ì‚¬ ì´ë²¤íŠ¸ í™•ì¸

Transcriptionì´ í™œì„±í™”ë˜ë©´ ë‹¤ìŒ ì´ë²¤íŠ¸ë“¤ì´ ìˆ˜ì‹ ë©ë‹ˆë‹¤:

### A. Input Audio Transcription (ì‚¬ìš©ì ë°œí™”)

```swift
case "conversation.item.input_audio_transcription.completed":
    if let transcript = event["transcript"] as? String {
        print("ğŸ“ User said: \(transcript)")
        // ê²Œì„ ë¡œì§: ì •ë‹µ íŒì •
        judgeAnswer(userAnswer: transcript)
    }

case "conversation.item.input_audio_transcription.delta":
    // ì‹¤ì‹œê°„ ì „ì‚¬ ì—…ë°ì´íŠ¸ (ì˜µì…˜)
    if let delta = event["delta"] as? String {
        print("ğŸ“ Delta: \(delta)")
        updateLiveTranscript(delta)
    }
```

### B. Output Audio Transcript (AI ë°œí™”)

```swift
case "response.output_audio_transcript.delta":
    if let delta = event["delta"] as? String {
        print("ğŸ¤– AI delta: \(delta)")
        updateAITranscript(delta)
    }

case "response.output_audio_transcript.done":
    if let transcript = event["transcript"] as? String {
        print("ğŸ¤– AI said: \(transcript)")
    }
```

## ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

Phase 1ì—ì„œ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  ì‚¬í•­:

- [ ] `session.created` ì´ë²¤íŠ¸ ìˆ˜ì‹ 
- [ ] `session.audio.input.transcription.model === "whisper-1"` í™•ì¸
- [ ] (í•„ìš”ì‹œ) `session.update` ì „ì†¡ ë° `session.updated` ìˆ˜ì‹ 
- [ ] ë§í•˜ê¸° í…ŒìŠ¤íŠ¸ í›„ `input_audio_buffer.speech_started` ìˆ˜ì‹ 
- [ ] `conversation.item.input_audio_transcription.completed` ìˆ˜ì‹ 
- [ ] ì „ì‚¬ëœ í…ìŠ¤íŠ¸ê°€ UIì— í‘œì‹œë¨
- [ ] AI ì‘ë‹µ í›„ `response.output_audio_transcript.delta` ìˆ˜ì‹ 

## ë¬¸ì œ í•´ê²°

### ì „ì‚¬ ì´ë²¤íŠ¸ê°€ ìˆ˜ì‹ ë˜ì§€ ì•ŠëŠ” ê²½ìš°

1. **Server config í™•ì¸**
   - Backend `index.js`ì—ì„œ `transcription: { model: "whisper-1" }` í¬í•¨ í™•ì¸

2. **DataChannel ìƒíƒœ í™•ì¸**
   ```swift
   print("DataChannel state: \(dataChannel.readyState.rawValue)")
   // 0: connecting, 1: open, 2: closing, 3: closed
   ```

3. **ëª¨ë“  ì„œë²„ ì´ë²¤íŠ¸ ë¡œê¹…**
   ```swift
   func dataChannel(_ dataChannel: RTCDataChannel, didReceiveMessageWith buffer: RTCDataBuffer) {
       let text = String(data: buffer.data, encoding: .utf8) ?? ""
       print("ğŸ“¥ RAW EVENT: \(text)")  // ëª¨ë“  ì´ë²¤íŠ¸ ì¶œë ¥

       // JSON íŒŒì‹±...
   }
   ```

4. **VAD ë™ì‘ í™•ì¸**
   - `input_audio_buffer.speech_started` ì´ë²¤íŠ¸ê°€ ë¨¼ì € ìˆ˜ì‹ ë˜ì–´ì•¼ í•¨
   - VADê°€ ë™ì‘í•˜ì§€ ì•Šìœ¼ë©´ ì „ì‚¬ë„ ì‹œì‘ë˜ì§€ ì•ŠìŒ

### VADê°€ ë™ì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš°

```swift
// session.updateë¡œ VAD ì¬ì„¤ì •
let event: [String: Any] = [
    "type": "session.update",
    "session": [
        "type": "realtime",
        "audio": [
            "input": [
                "turn_detection": [
                    "type": "semantic_vad",
                    "threshold": 0.3,  // ë” ë¯¼ê°í•˜ê²Œ (ê¸°ë³¸ 0.5)
                    "silence_duration_ms": 500,
                    "prefix_padding_ms": 300
                ]
            ]
        ]
    ]
]
```

## ì½”ë“œ í…œí”Œë¦¿

ì™„ì „í•œ ê²€ì¦ ì½”ë“œ:

```swift
// RealtimeWebRTCClient.swift

var isTranscriptionActive = false

func handleServerEvent(_ event: [String: Any]) {
    guard let type = event["type"] as? String else { return }

    print("ğŸ“¥ Event: \(type)")

    switch type {
    case "session.created":
        verifyTranscriptionEnabled(in: event)

    case "session.updated":
        verifyTranscriptionEnabled(in: event)

    case "input_audio_buffer.speech_started":
        print("ğŸ¤ User started speaking")

    case "input_audio_buffer.speech_stopped":
        print("ğŸ¤ User stopped speaking")

    case "conversation.item.input_audio_transcription.completed":
        handleUserTranscript(event)

    case "response.output_audio_transcript.delta":
        handleAITranscriptDelta(event)

    default:
        break
    }
}

private func verifyTranscriptionEnabled(in event: [String: Any]) {
    if let session = event["session"] as? [String: Any],
       let audio = session["audio"] as? [String: Any],
       let input = audio["input"] as? [String: Any],
       let transcription = input["transcription"] as? [String: Any],
       let model = transcription["model"] as? String {

        print("âœ… Transcription active: \(model)")
        isTranscriptionActive = true

    } else {
        print("âš ï¸ Transcription NOT active - activating now")
        isTranscriptionActive = false
        activateTranscription()
    }
}

private func handleUserTranscript(_ event: [String: Any]) {
    guard let transcript = event["transcript"] as? String else { return }

    print("ğŸ“ User transcript: \(transcript)")
    delegate?.realtimeClient(self, didReceiveUserTranscript: transcript)
}

private func handleAITranscriptDelta(_ event: [String: Any]) {
    guard let delta = event["delta"] as? String else { return }

    print("ğŸ¤– AI delta: \(delta)")
    delegate?.realtimeClient(self, didReceiveAITranscriptDelta: delta)
}
```

---

**ì‘ì„±ì¼**: 2025-12-19
**Phase**: Phase 1 ê²€ì¦ ë‹¨ê³„
**ì¤‘ìš”ë„**: ğŸ”´ Critical - ì „ì‚¬ê°€ ì—†ìœ¼ë©´ ê²Œì„ ë™ì‘ ë¶ˆê°€
